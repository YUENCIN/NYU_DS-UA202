{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "“HW1_template_DS_UA_202”的副本",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43DBqagWutAE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**RDS (DS-UA 202) Spring 2022: Homework 1 Template**\n",
    "\n",
    "\n",
    "This notebook is a template for problem 2. You should save a copy of this notebook and write your code in that copy. The code to setup the analysis is provided for you here. You should not edit or add to the setup code.\n",
    "\n",
    "Some suggested steps are included as comments in the below code cells. You do not need to follow these suggestions (other solutions or approaches are acceptable)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "id": "uCxmXPdjC78N",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Packages"
   ],
   "metadata": {
    "id": "8nSrlba1Hm3u",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/lurosenb/superquail\n",
    "!pip install aif360==0.3.0 \n",
    "!pip install BlackBoxAuditing\n",
    "!pip install tensorflow==1.13.1\n",
    "!pip install folktables"
   ],
   "metadata": {
    "id": "gtYGFyqSm2nk",
    "outputId": "c096015d-b0f2-46c6-aa2b-e21fb981c771",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'superquail'...\n",
      "remote: Enumerating objects: 24, done.\u001B[K\n",
      "remote: Counting objects: 100% (24/24), done.\u001B[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001B[K\n",
      "remote: Total 24 (delta 1), reused 20 (delta 1), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (24/24), done.\n",
      "Collecting aif360==0.3.0\n",
      "  Downloading aif360-0.3.0-py3-none-any.whl (165 kB)\n",
      "\u001B[K     |████████████████████████████████| 165 kB 22.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.3.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (3.2.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from aif360==0.3.0) (1.0.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360==0.3.0) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360==0.3.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360==0.3.0) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->aif360==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->aif360==0.3.0) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.3.0) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.3.0) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.3.0) (0.11.0)\n",
      "Installing collected packages: aif360\n",
      "Successfully installed aif360-0.3.0\n",
      "Collecting BlackBoxAuditing\n",
      "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.6 MB 11.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->BlackBoxAuditing) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n",
      "Building wheels for collected packages: BlackBoxAuditing\n",
      "  Building wheel for BlackBoxAuditing (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394770 sha256=111815441729803e05baa792374570cd47dc8a07db99746fc897ecccfd2f512f\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/9f/ee/541a74be4cf5dad17430e64d3276370ea7b6a834a76cb4215a\n",
      "Successfully built BlackBoxAuditing\n",
      "Installing collected packages: BlackBoxAuditing\n",
      "Successfully installed BlackBoxAuditing-0.1.54\n",
      "Collecting tensorflow==1.13.1\n",
      "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 92.6 MB 57 kB/s \n",
      "\u001B[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.43.0)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001B[K     |████████████████████████████████| 367 kB 41.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.21.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.2 MB 42.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.5.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001B[K     |████████████████████████████████| 50 kB 2.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n",
      "Collecting mock>=2.0.0\n",
      "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
      "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.0\n",
      "    Uninstalling tensorflow-2.8.0:\n",
      "      Successfully uninstalled tensorflow-2.8.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001B[0m\n",
      "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n",
      "Collecting folktables\n",
      "  Downloading folktables-0.0.11.tar.gz (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folktables) (1.21.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from folktables) (1.3.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folktables) (2.23.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from folktables) (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->folktables) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->folktables) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->folktables) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folktables) (2.10)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->folktables) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->folktables) (1.1.0)\n",
      "Building wheels for collected packages: folktables\n",
      "  Building wheel for folktables (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for folktables: filename=folktables-0.0.11-py3-none-any.whl size=6779 sha256=f404030e278789a8ac9c5aa3f82f99fa3f729095cde6a6c67b9444bbaa264e94\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/63/b8/24d3f5d2c70002c68c1fe8e78e1de20fcbcb7a2ef3f56147b7\n",
      "Successfully built folktables\n",
      "Installing collected packages: folktables\n",
      "Successfully installed folktables-0.0.11\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-BAY1cNGuxfk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import random\n",
    "random.seed(6)\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from folktables import ACSDataSource, ACSEmployment, ACSIncome, ACSPublicCoverage, ACSTravelTime\n",
    "from superquail.data.acs_helper import ACSData\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing, RejectOptionClassification\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "from aif360.sklearn.preprocessing import ReweighingMeta\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "from aif360.sklearn.datasets import fetch_adult\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio, average_odds_error, generalized_fpr\n",
    "from aif360.sklearn.metrics import generalized_fnr, difference\n",
    "\n",
    "import BlackBoxAuditing\n",
    "%matplotlib inline"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW83Vu3KvTQB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have included code to read in the folktables dataset. The Folktables dataset is taken from US Census Data and is built to solve a few simple prediction tasks. The sample we pull is data from 2018 in California. The column names are described in the table below. Note that certain categorical variables have been mapped to integer values, which we will keep as is for the following analyses.\n",
    "\n",
    "For more information on the this dataset, please see the following paper:\n",
    "https://eaamo2021.eaamo.org/accepted/acceptednonarchival/EAMO21_paper_16.pdf"
   ],
   "metadata": {
    "id": "UH30OASO5pf3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Column Name | Feature | Description/Notes |\n",
    "| --- | ----------- | --- |\n",
    "| PINCP | Total person’s income | (Target) 1 if >= $50k, 0 if less |\n",
    "| SEX | Sex | (Sensitive Attribute) Male=1, Female=2 |\n",
    "| RAC1P | Race | Dropped from this analysis to focus on one sensitive attribute |\n",
    "| AGEP | Age | Ranges from 0-99 |\n",
    "| COW | Class of Worker | Ranges 1-9, see paper for description |\n",
    "| SCHL | Education Level | Ranges 1-24, see paper for description |\n",
    "| MAR | Marital Status | Ranges 1-5, see paper for description |\n",
    "| OCCP | Occupation | Codes taken from Public Use Microdata Sample (PUMS) from the US Census, see paper |\n",
    "| POBP | Place of Birth | Codes taken from Public Use Microdata Sample (PUMS) from the US Census, see paper |\n",
    "| RELP | Relationship | Relationship of individual to person who responded to the Census taker. Ranges 0-17, see paper for description |\n",
    "| WKHP | Hours worked per week | Ranges from 0-99, averaged over previous year |"
   ],
   "metadata": {
    "id": "ErJSui-veHGd",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "np.random.seed(13) # do not change the seed\n",
    "\n",
    "# read in the folktables dataset \n",
    "full_df, features_df, target_df, groups_df = ACSData().return_acs_data_scenario(scenario=\"ACSIncome\", subsample=30000)\n",
    "full_df = full_df.drop(columns='RAC1P') # drop race -- another protected attribute from our dataset\n",
    "\n",
    "print(full_df.shape)\n",
    "full_df.head()"
   ],
   "metadata": {
    "id": "JKV2cQ_Q3IqF",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "outputId": "5997003f-d06c-4381-9b95-054295a2586b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data for 2018 1-Year person survey for CA...\n",
      "(30000, 10)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-43e326ee-51fe-4eb2-ab1c-29513c914b52\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4720.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43e326ee-51fe-4eb2-ab1c-29513c914b52')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-43e326ee-51fe-4eb2-ab1c-29513c914b52 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-43e326ee-51fe-4eb2-ab1c-29513c914b52');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  PINCP\n",
       "0  44.0  1.0   1.0  1.0  4220.0    6.0  10.0  40.0  1.0    0.0\n",
       "1  66.0  2.0  20.0  2.0  4720.0   42.0   0.0  32.0  2.0    0.0\n",
       "2  72.0  6.0  18.0  1.0    10.0    6.0   1.0   8.0  2.0    1.0\n",
       "3  53.0  1.0  21.0  1.0  1460.0  457.0   0.0  40.0  1.0    1.0\n",
       "4  55.0  1.0  16.0  1.0   220.0    6.0   1.0  40.0  1.0    0.0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set protected attribute and target"
   ],
   "metadata": {
    "id": "HBFTP1NJJQHy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "protected_attr = 'SEX' # set sex as the protected attribute\n",
    "target = 'PINCP' # personal income as the target, note that [1 = >50k]"
   ],
   "metadata": {
    "id": "z9rLvp4tJHy2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# convert this dataframe into an aif360 dataset\n",
    "original_data = BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=full_df,\n",
    "    label_names=[target],\n",
    "    protected_attribute_names=[protected_attr])\n",
    "privileged_groups = [{protected_attr: 1}] \n",
    "unprivileged_groups = [{protected_attr: 2}]"
   ],
   "metadata": {
    "id": "cEZljEsG4G1j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data"
   ],
   "metadata": {
    "id": "54wA6QWtHrzJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "seed = 50\n",
    "train_data, test_data = original_data.split([0.8], shuffle=True, seed=seed)"
   ],
   "metadata": {
    "id": "9NjSSl8iEmne",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale features in the data"
   ],
   "metadata": {
    "id": "4tVEqq34H1ZH",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data.features = scaler.fit_transform(train_data.features)\n",
    "test_data.features = scaler.transform(test_data.features)\n",
    "\n",
    "# convert to dataframes\n",
    "train_df, _ = train_data.convert_to_dataframe()\n",
    "test_df, _ = test_data.convert_to_dataframe()\n",
    "print(\"Training set: \", train_df.shape)\n",
    "print(\"Test set: \", test_df.shape)\n",
    "\n",
    "# extract x (features) and y (target)\n",
    "train_x = train_df.drop([target, protected_attr], axis=1)\n",
    "train_y = train_df[target]\n",
    "test_x = test_df.drop([target, protected_attr], axis=1)\n",
    "test_y = test_df[target]"
   ],
   "metadata": {
    "id": "Aa2GzY3HE-l_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "61e70d23-e97d-4d13-efdc-b178ee656957",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set:  (24000, 10)\n",
      "Test set:  (6000, 10)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaQZc9mkDBQc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_9U8nMU3pg0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train a random forest model (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bo149tbl3n_N",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e628ab64-6446-4e8e-cd21-8050a8d8b8d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# use these hyperparameters in your call to RandomForestClassifier\n",
    "n_estimators = 20\n",
    "max_depth = 10\n",
    "\n",
    "# set up the random forest model, using the hyperparameters\n",
    "model = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth) \n",
    "\n",
    "# fit the model using the training data (train_x, train_y)\n",
    "model.fit(train_x,train_y)\n"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=20)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci-ClRL14Efm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# the below function has been provided for you. You can use this function to\n",
    "# convert your data to a StandardDataset format for use in AIF360\n",
    "def transform_to_aif(df, target=target, protected_attr=protected_attr):\n",
    "  '''convert a pandas.DataFrame to a StandardDataset used in AIF360'''\n",
    "\n",
    "  sd = StandardDataset(\n",
    "      df,\n",
    "      label_name = target,\n",
    "      favorable_classes = [1],\n",
    "      protected_attribute_names = [protected_attr],\n",
    "      privileged_classes = [[1]]\n",
    "  )\n",
    "\n",
    "  return sd"
   ],
   "metadata": {
    "id": "KbbYXuCw9D7a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate predictions from baseline RF model\n",
    "y_predict = model.predict(test_x)\n",
    "\n",
    "# convert predictions data to AIF StandardDataset\n",
    "predict_df = test_df.copy()\n",
    "predict_df[target] = y_predict\n",
    "predict_sd = transform_to_aif(predict_df)\n",
    "print(predict_sd)\n",
    "\n",
    "# also create AIF StandardDataset versions of training and test data\n",
    "train_sd = transform_to_aif(train_df)\n",
    "test_sd = transform_to_aif(test_df)\n",
    "print(test_sd)"
   ],
   "metadata": {
    "id": "NZASQVuR6R0t",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0df0ed08-216b-4a76-ba45-df1343bcf480",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 83,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               instance weights  features  ...                     labels\n",
      "                                           ... protected attribute       \n",
      "                                     AGEP  ...                 SEX       \n",
      "instance names                             ...                           \n",
      "4252                        1.0  0.077922  ...                 1.0    0.0\n",
      "17560                       1.0  0.480519  ...                 2.0    1.0\n",
      "13863                       1.0  0.519481  ...                 2.0    0.0\n",
      "19541                       1.0  0.376623  ...                 1.0    1.0\n",
      "19879                       1.0  0.571429  ...                 2.0    1.0\n",
      "...                         ...       ...  ...                 ...    ...\n",
      "15649                       1.0  0.194805  ...                 2.0    0.0\n",
      "22637                       1.0  0.233766  ...                 2.0    0.0\n",
      "10123                       1.0  0.480519  ...                 1.0    1.0\n",
      "5600                        1.0  0.467532  ...                 1.0    0.0\n",
      "14000                       1.0  0.454545  ...                 1.0    1.0\n",
      "\n",
      "[6000 rows x 11 columns]\n",
      "               instance weights  features  ...                     labels\n",
      "                                           ... protected attribute       \n",
      "                                     AGEP  ...                 SEX       \n",
      "instance names                             ...                           \n",
      "4252                        1.0  0.077922  ...                 1.0    0.0\n",
      "17560                       1.0  0.480519  ...                 2.0    0.0\n",
      "13863                       1.0  0.519481  ...                 2.0    0.0\n",
      "19541                       1.0  0.376623  ...                 1.0    1.0\n",
      "19879                       1.0  0.571429  ...                 2.0    1.0\n",
      "...                         ...       ...  ...                 ...    ...\n",
      "15649                       1.0  0.194805  ...                 2.0    0.0\n",
      "22637                       1.0  0.233766  ...                 2.0    0.0\n",
      "10123                       1.0  0.480519  ...                 1.0    1.0\n",
      "5600                        1.0  0.467532  ...                 1.0    0.0\n",
      "14000                       1.0  0.454545  ...                 1.0    1.0\n",
      "\n",
      "[6000 rows x 11 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# calculate metrics\n",
    "overall_accu = accuracy_score(test_y, y_predict)\n",
    "res_cl = ClassificationMetric(test_sd, predict_sd)\n",
    "\n",
    "ov_accu = res_cl.accuracy\n",
    "pg_accu = 0\n",
    "ug_accu = 0\n",
    "di = res_cl.disparate_impact\n",
    "fpr = 0\n",
    "print(ov_accu)\n",
    "print(di)"
   ],
   "metadata": {
    "id": "1pUBPJoXBS7O",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "outputId": "d739291f-b3ad-4685-9051-a297dd6e1d09",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 98,
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-98-91ac711dc48b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mres_cl\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mClassificationMetric\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_sd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredict_sd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mov_accu\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mres_cl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetric_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mpg_accu\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mug_accu\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'metric_values'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKhDj-XJRUJL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform the original data using Disparate Impact Remover at five repair levels and calculate metrics"
   ],
   "metadata": {
    "id": "FC7yhPhEH_Q7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8NToBvrQiWIz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# the below function has been provided for you. You can use this function to\n",
    "# plot the repair_level (on the x-axis) against a given metric,\n",
    "# e.g. accuracy, on the y-axis\n",
    "def plot_metric_repair(repair_levels, metric_values, metric_name):\n",
    "  '''Creates a line plot showing how the metric changed for different values of repair level'''\n",
    "\n",
    "  # Plot the metrics\n",
    "  plt.plot(repair_levels, metric_values, color='#0384fc', linewidth=3, label=metric_name)\n",
    "\n",
    "  # Create labels, etc. \n",
    "  plt.xlabel('Repair level')\n",
    "  plt.ylabel(metric_name)\n",
    "  plt.legend()\n",
    "  plt.show()"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# use these repair levels\n",
    "repair_levels = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "# transform the test and training data using DI-remover at the above repair\n",
    "DIs = []\n",
    "train_repds = []\n",
    "test_repds = []\n",
    "for level in repair_levels:\n",
    "  di = DisparateImpactRemover(repair_level=level)\n",
    "  train_repd = di.fit_transform(train_data)\n",
    "  test_repd = di.fit_transform(test_data)\n",
    "  train_repds.append(train_repd)\n",
    "  test_repds.append(test_repd)\n",
    "# levels and calculate metrics (you may wish to use a for loop)\n",
    "\n",
    "    "
   ],
   "metadata": {
    "id": "ffAzfF7tH-Y8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot each metric against the repair level\n",
    "# (you can use the plot_metric_repair above)\n",
    "#plot_metric_repair(repair_levels,)\n"
   ],
   "metadata": {
    "id": "WYmYGrwWRoeP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "outputId": "dd6ddf3f-d77a-464d-a308-bee44afd0944",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-14f378583613>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# plot each metric against the repair level\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# (you can use the plot_metric_repair above)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mplot_metric_repair\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrepair_levels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: plot_metric_repair() missing 2 required positional arguments: 'metric_values' and 'metric_name'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 (c) \n"
   ],
   "metadata": {
    "id": "gu1xtZ6ExCdU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a Prejudice Remover model at three eta values and calculate metrics\n"
   ],
   "metadata": {
    "id": "APeTeITlhm4B",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "etas = [0.01, 0.1, 1] # eta is the weight we apply to the fairness regularization parameter\n",
    "\n",
    "# train a Prejudice Remover model at these eta values and calculate metrics\n",
    "# (you may wish to use a for loop)\n"
   ],
   "metadata": {
    "id": "NiejOOrrfEiG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot one or more of the metrics varies at the different values of eta\n"
   ],
   "metadata": {
    "id": "FZ16AQ9frCRt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}